# -*- coding: utf-8 -*-
"""DM_Project_Final_with_Frontend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EmUUjU_cb2yGBOW_APsPuSAHxEmVacrp



import pandas as pd
import numpy as np
from datetime import datetime
import re
from urllib.parse import urlparse

import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
!pip install AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve,
    precision_score,
    recall_score,
    f1_score
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

import kagglehub
from kagglehub import KaggleDatasetAdapter
!pip install catboost
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

"""#Problem Statement"""

problem_statement = """
Phishing Email Detection using Multi-Modal Learning

Phishing emails remain one of the most critical cybersecurity threats, aiming to trick recipients into
revealing sensitive information. Traditional detection systems have focused on either text-based or
URL-based features. In this project, we propose a multi-modal approach that integrates both types of
features to enhance detection performance. By leveraging natural language processing (NLP) for textual
data and parsing URL metadata, the system is expected to better differentiate phishing attempts from
legitimate emails. This project will utilize a public dataset from Kaggle to build and evaluate a range
of models, from classic machine learning classifiers to advanced deep learning architectures.
"""
print(problem_statement)

"""Loading the dataset"""

dataset_url = "https://www.kaggle.com/datasets/naserabdullahalam/phishing-email-dataset"
print("Dataset Link:", dataset_url)

data_path = "phishing_email_dataset.csv"
df = pd.read_csv(data_path)

print("Dataset Shape:", df.shape)
print("Dataset Columns:", df.columns.tolist())
print(df.head())

"""#Handling Missing Values

Drop rows where key fields (body, subject, sender, or urls) are missing
"""

df.dropna(subset=['body', 'subject', 'sender', 'urls'], inplace=True)
print("Shape after dropping missing key fields:", df.shape)

# --- Text Cleaning Functions ---
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text, apply_lemmatization=False):
    text = str(text).lower()                          # Lowercase
    text = re.sub(r'\[.*?\]', '', text)                # Remove text in brackets
    text = re.sub(r'https?://\S+|www\.\S+', '', text)   # Remove URLs
    text = re.sub(r'<.*?>+', '', text)                 # Remove HTML tags
    text = re.sub(r'[%s]' % re.escape('!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'), '', text)  # Remove punctuation
    text = re.sub(r'\n', ' ', text)                    # Remove newline characters
    text = re.sub(r'\w*\d\w*', '', text)               # Remove words containing numbers
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords
    if apply_lemmatization:
        tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return " ".join(tokens)

# Clean both 'body' and 'subject' with lemmatization enabled
df['clean_body'] = df['body'].apply(lambda x: clean_text(x, apply_lemmatization=True))
df['clean_subject'] = df['subject'].apply(lambda x: clean_text(x, apply_lemmatization=True))

# Create additional text-based features
df['body_length'] = df['clean_body'].apply(len)
df['subject_length'] = df['clean_subject'].apply(len)

def extract_url_features(url_str):
    # Ensure the input is a string
    url_str = str(url_str)
    # Use regex to find all URLs in the string
    urls = re.findall(r'(https?://\S+)', url_str)
    # Extract domain names from the URLs, handling potential IPv6 errors
    domains = []
    for url in urls:
        try:
            parsed_url = urlparse(url)
            if parsed_url.netloc:  # Check if netloc is not empty
                domains.append(parsed_url.netloc)
        except ValueError as e:
            print(f"Error parsing URL: {url}, Error: {e}")
    num_urls = len(urls)
    # Calculate average domain length; use 0 if there are no domains
    avg_domain_length = np.mean([len(d) for d in domains]) if domains else 0
    return pd.Series([num_urls, avg_domain_length, domains])

df['urls'] = df['urls'].fillna('')
df[['num_urls', 'avg_domain_length', 'domains']] = df['body'].apply(extract_url_features)

# --- Sender Domain Extraction ---
def extract_sender_domain(sender):
    # Extract domain from sender email
    match = re.search(r'@([\w\.-]+)', sender)
    if match:
        return match.group(1)
    return ""

df['sender_domain'] = df['sender'].apply(extract_sender_domain)

df.head(10)

# -------------------------------
# 4) Preliminary Insights & Visualizations
# -------------------------------

# Visualization 1: Distribution of Email Labels
plt.figure(figsize=(6, 4))
sns.countplot(x='label', data=df, palette="viridis")
plt.title('Distribution of Email Labels')
plt.xlabel('Label (0 = Legitimate, 1 = Phishing)')
plt.ylabel('Count')
plt.show()

# Visualization 2: Distribution of Email Body Lengths
plt.figure(figsize=(6, 4))
sns.histplot(df['body_length'], bins=30, kde=True, color='steelblue')
plt.title('Distribution of Email Body Lengths')
plt.xlabel('Length of Email Body')
plt.ylabel('Frequency')
plt.show()

# Visualization 3: Word Cloud for Phishing Emails (Label == 1)
phishing_text = " ".join(df[df['label'] == 1]['clean_body'].tolist())
wordcloud_phishing = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(phishing_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_phishing, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Phishing Emails')
plt.show()

# Visualization 4: Word Cloud for Legitimate Emails (Label == 0)
legit_text = " ".join(df[df['label'] == 0]['clean_body'].tolist())
wordcloud_legit = WordCloud(width=800, height=400, background_color='white', colormap='plasma').generate(legit_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_legit, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Legitimate Emails')
plt.show()

# Visualization 5: Boxplot of Email Body Lengths by Label
plt.figure(figsize=(6, 4))
sns.boxplot(x='label', y='body_length', data=df, palette="Set2")
plt.title('Email Body Lengths by Label')
plt.xlabel('Label (0 = Legitimate, 1 = Phishing)')
plt.ylabel('Body Length')
plt.show()

# Visualization 7: Sender Domain Frequency (Top 10 Domains)
top_domains = df['sender_domain'].value_counts().head(10)
plt.figure(figsize=(8, 4))
sns.barplot(x=top_domains.index, y=top_domains.values, palette="coolwarm")
plt.title('Top 10 Sender Domains')
plt.xlabel('Sender Domain')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

# Visualization 8: Correlation Heatmap of Numeric Features
plt.figure(figsize=(8, 6))
numeric_features = df[['body_length', 'subject_length', 'num_urls', 'avg_domain_length', 'label']]
corr = numeric_features.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap of Numeric Features')
plt.show()

print("Summary Statistics:")
print(df.describe())

df.head()

"""# Modelling"""

# Define features and labels
X_raw = df[['body', 'subject']]
y = df['label']
X_preprocessed = df[['clean_body', 'clean_subject', 'body_length', 'subject_length', 'num_urls', 'avg_domain_length']]

# Split data
X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42)
X_train_preprocessed, X_test_preprocessed, _, _ = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)

# Define feature lists
text_features = ['body', 'subject']
preprocessed_text_features = ['clean_body', 'clean_subject']
numerical_features = ['body_length', 'subject_length', 'num_urls', 'avg_domain_length']

# Define preprocessors
preprocessor_raw = ColumnTransformer(
    transformers=[
        ('text_body', TfidfVectorizer(), 'body'),
        ('text_subject', TfidfVectorizer(), 'subject'),
    ]
)

preprocessor_preprocessed = ColumnTransformer(
    transformers=[
        ('text_clean_body', TfidfVectorizer(), 'clean_body'),
        ('text_clean_subject', TfidfVectorizer(), 'clean_subject'),
        ('numerical', 'passthrough', numerical_features)
    ]
)

lr_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', LogisticRegression(max_iter=2000))
])

lr_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', LogisticRegression(max_iter=2000))
])

rf_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', RandomForestClassifier(random_state=42))
])

rf_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', RandomForestClassifier(random_state=42))
])

xgb_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', XGBClassifier(random_state=42, eval_metric='logloss'))
])

xgb_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', XGBClassifier(random_state=42, eval_metric='logloss'))
])

extratrees_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', ExtraTreesClassifier(random_state=42))
])

extratrees_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', ExtraTreesClassifier(random_state=42))
])

gb_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', GradientBoostingClassifier(random_state=42))
])

gb_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', GradientBoostingClassifier(random_state=42))
])

knn_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', KNeighborsClassifier(n_neighbors=3))
])

knn_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', KNeighborsClassifier(n_neighbors=3))
])

dt_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', DecisionTreeClassifier(max_depth=3, random_state=42))
])

dt_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', DecisionTreeClassifier(max_depth=3, random_state=42))
])

pa_pipeline_raw = Pipeline([
    ('preprocessor', preprocessor_raw),
    ('classifier', PassiveAggressiveClassifier(max_iter=50, random_state=42))
])

pa_pipeline_preprocessed = Pipeline([
    ('preprocessor', preprocessor_preprocessed),
    ('classifier', PassiveAggressiveClassifier(max_iter=50, random_state=42))
])

# Models dictionary
models = {
    "Logistic Regression (Raw)": lr_pipeline_raw,
    "Logistic Regression (Preprocessed)": lr_pipeline_preprocessed,
    "Random Forest (Raw)": rf_pipeline_raw,
    "Random Forest (Preprocessed)": rf_pipeline_preprocessed,
    "XGBoost (Raw)": xgb_pipeline_raw,
    "XGBoost (Preprocessed)": xgb_pipeline_preprocessed,
    "ExtraTrees (Raw)": extratrees_pipeline_raw,
    "ExtraTrees (Preprocessed)": extratrees_pipeline_preprocessed,
    "Gradient Boosting (Raw)": gb_pipeline_raw,
    "Gradient Boosting (Preprocessed)": gb_pipeline_preprocessed,
    "K-Nearest Neighbors (Raw)": knn_pipeline_raw,
    "K-Nearest Neighbors (Preprocessed)": knn_pipeline_preprocessed,
    "Decision Tree (Raw)": dt_pipeline_raw,
    "Decision Tree (Preprocessed)": dt_pipeline_preprocessed,
    "Passive Aggressive (Raw)": pa_pipeline_raw,
    "Passive Aggressive (Preprocessed)": pa_pipeline_preprocessed
}

results = {}
for name, model in models.items():
    print(f"Training {name}...")
    is_preprocessed = "Preprocessed" in name
    X_train = X_train_preprocessed if is_preprocessed else X_train_raw
    X_test = X_test_preprocessed if is_preprocessed else X_test_raw

    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    y_prob = None
    if hasattr(model.named_steps['classifier'], 'predict_proba'):
        y_prob = model.predict_proba(X_test)[:, 1]
    elif hasattr(model.named_steps['classifier'], 'decision_function'):
        y_prob = model.decision_function(X_test)

    accuracy = (y_pred == y_test).mean()
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else 0

    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "ROC-AUC": roc_auc
    }

# Print results
print("\nFinal Results:")
for name, metrics in results.items():
    print(f"\n{name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.4f}")

X_raw = df['body']
X_preprocessed = df['clean_body']
y = df['label']

X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y, test_size=0.2, random_state=42)
X_train_preprocessed, X_test_preprocessed, y_train_preprocessed, y_test_preprocessed = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)

def prepare_data(texts_train, texts_test, max_words=10000, max_len=100):
    tokenizer = Tokenizer(num_words=max_words)
    tokenizer.fit_on_texts(texts_train)

    X_train_seq = tokenizer.texts_to_sequences(texts_train)
    X_test_seq = tokenizer.texts_to_sequences(texts_test)

    X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
    X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')

    return X_train_pad, X_test_pad, tokenizer


X_train_raw_pad, X_test_raw_pad, tokenizer_raw = prepare_data(X_train_raw, X_test_raw)
X_train_preprocessed_pad, X_test_preprocessed_pad, tokenizer_preprocessed = prepare_data(X_train_preprocessed, X_test_preprocessed)

def build_lstm_model(max_words, max_len, embedding_dim=100):
    model = Sequential([
        Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len),
        LSTM(128, return_sequences=False),  # LSTM layer with 128 units
        Dropout(0.5),                      # Dropout for regularization
        Dense(64, activation='relu'),      # Fully connected layer
        Dropout(0.5),                      # Additional dropout
        Dense(1, activation='sigmoid')     # Output layer for binary classification
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

def train_and_evaluate_lstm(model, X_train, X_test, y_train, y_test, name):
    print(f"Training LSTM on {name}...")
    history = model.fit(
        X_train,
        y_train,
        epochs=1,
        batch_size=32,
        validation_split=0.2,
        verbose=1
    )

    y_pred_prob = model.predict(X_test).flatten()
    y_pred = (y_pred_prob > 0.5).astype(int)

    results = {
        "Accuracy": (y_pred == y_test).mean(),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1-Score": f1_score(y_test, y_pred),
        "ROC-AUC": roc_auc_score(y_test, y_pred_prob)
    }

    print(f"LSTM Results ({name}):")
    print(results)

    def plot_confusion_matrix(y_true, y_pred, title):
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
        plt.title(title)
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.show()

    plot_confusion_matrix(y_test, y_pred, f"Confusion Matrix - LSTM ({name})")

    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f"LSTM ({name}) (AUC={results['ROC-AUC']:.2f})")
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve - LSTM ({name})")
    plt.legend()
    plt.show()

    return results

max_words = 10000
max_len = 100

lstm_model_raw = build_lstm_model(max_words, max_len)
lstm_results_raw = train_and_evaluate_lstm(lstm_model_raw, X_train_raw_pad, X_test_raw_pad, y_train_raw, y_test_raw, "Raw Data")

lstm_model_preprocessed = build_lstm_model(max_words, max_len)
lstm_results_preprocessed = train_and_evaluate_lstm(lstm_model_preprocessed, X_train_preprocessed_pad, X_test_preprocessed_pad, y_train_preprocessed, y_test_preprocessed, "Preprocessed Data")

!pip install gradio
import gradio as gr
import pandas as pd
from tensorflow.keras.preprocessing.sequence import pad_sequences

def predict_phishing_email(sender, subject, body):
    global tokenizer_preprocessed, lstm_model_preprocessed

    email_data = pd.DataFrame({
        'sender': [sender],
        'subject': [subject],
        'body': [body],
        'urls': ['']
    })

    email_data['clean_body'] = email_data['body'].apply(lambda x: clean_text(x, apply_lemmatization=True))
    email_data['clean_subject'] = email_data['subject'].apply(lambda x: clean_text(x, apply_lemmatization=True))
    email_data['body_length'] = email_data['clean_body'].apply(len)
    email_data['subject_length'] = email_data['clean_subject'].apply(len)
    email_data[['num_urls', 'avg_domain_length', 'domains']] = email_data['body'].apply(extract_url_features)
    email_data['sender_domain'] = email_data['sender'].apply(extract_sender_domain)

    X_seq = tokenizer_preprocessed.texts_to_sequences(email_data['clean_body'])
    X_pad = pad_sequences(X_seq, maxlen=100, padding='post')
    prediction_prob = lstm_model_preprocessed.predict(X_pad, verbose=0).flatten()[0]
    prediction = 1 if prediction_prob > 0.5 else 0
    confidence = prediction_prob if prediction == 1 else 1 - prediction_prob

    label = "Phishing" if prediction == 1 else "Legitimate"
    return f"Prediction: {label}\nConfidence: {confidence:.4f}"

interface = gr.Interface(
    fn=predict_phishing_email,
    inputs=[
        gr.Textbox(label="Sender (e.g., Name <email@domain.com>)", placeholder="Enter sender email"),
        gr.Textbox(label="Subject", placeholder="Enter email subject"),
        gr.Textbox(label="Body", placeholder="Enter email body", lines=5)
    ],
    outputs=gr.Textbox(label="Prediction Result"),
    title="Phishing Email Detector (LSTM)",
    description="Enter the sender, subject, and body of an email to predict if itâ€™s phishing or not.",
    allow_flagging="never"
)

interface.launch()

